# leads.aiworkplace
Ключевая идея - сделать простой микросервис на PHP, полностью сгенерированный и сопровождаемый AI-агентами Cursor

1. За основу взят шаблон: Vibe-Coding-Template [https://github.com/jpke/cursor-vibe-coding-template]
2. Добавлены Cursor Rules для PHP: Awesome-cursorrules[https://github.com/PatrickJS/awesome-cursorrules]
3. Настроен и инициирован планировщик работ: TaskMaster[https://www.task-master.dev/]
4. С помощью Perplexity проверен prd.txt и декомпозиция: Perplexity AI [https://www.perplexity.ai/]
5. Донастроены MCP-тулы работы с Git

## Цель сервиса:
- простенький PHP микросервис на базе Slim PHP с чистой архитектурой для обработки лидов с сайта
- замерить качество и стоимость разработки

## Задачи:
- планирование и декомпозиция задачи (Task Master)
- чистая архитектура на PHP (Cursor Rules)
- соблюдение workflow процессов разработки (Cursor Rules)
- ведение git issues, соблюдение git-flow и PR (Github MCP)
- создать POST метод, принимает заявку с формы, сохраняет в amoCRM
- упаковка и запуск в Docker
- обеспечить безопасность данных (.env, .config и прочие)
- написание автотестов
- описание документации по завершению

## Результат эксперимента:

### ЭТАП 1: Планирование
Если описать качественный PRD файл, то AI неплохо распланирует задачи. Я провалидировал мысли и декомопзицию с помощью Perplexity. Cursor, TaskMaster и AI-агенты неплохо справились с поставленной задачей. Результатом планирования - автоматически создан Github Issue [https://github.com/kibarik/simple-backend-microservice/issues/1] и нарезаны задачи в .taskmaster/tasks

PS По опыту прошлых проектов - качество планирования напрямую определяет качество проекта

### ЭТАП 2: исполнение первичного плана
AI-агенты следуют Workflow и вызывают TaskMaster, шаг за шагом реализуют задачу. Каждый шаг аргументированно и разложенно - понятно что и в какой последовательности происходит и как меняется код. После завершения генерации - оформляет git commit. На этом этапе никаких проблем не было - просто ждал когда AI доделает шаг, открывал нового агента и стартовал следующий шаг. Очень нравится точность вызова MCP-тулов и качество работы самих тулов (TaskMaster, Github, Docker, Code)

На выходе - получился полноценный Github проект с архитектурой, документацией, тестами, git историей, Docker. Заняла генерация около 30-ти минут и 5$ из подписки. 

### ЭТАП 3: Первый запуск и отладка
Отправил задачу запустить - Cursor через терминал запустил Docker и сам фиксил ошибки. Через Curl проверял состояния, ловил ошибки и дебажил пока не получил ожидаемые ответы по каждой ручке. 

Далее попросил его прогнать тесты - AI нашел ошибки и около 30 минут дописывал код под свои же корректировки. Еще он забывал коммитить изменения и из-за этого получалась каша.

## ЭТАП 4: Отладка и тестирование
Проведено комплексное тестирование API создания лидов через curl. Система работает корректно:


### ЭТАП 4: Коннект с Frontend проектом
Поставил настройки во Frontend форме с другого проекта. 

### ЭТАП 5: PreProduction отладка

### ЭТАП 6: Деплой в Production

### Финал
Результат:
Время:
Стоимость:

## Что хочется улучшить
Мне уже нравится качество на этапе следования плана. Проблема на этапе проверки. Думаю главное - это внедрить TDD методологию, чтобы у AI-системы сразу было понятие работает/не работает. Пусть AI-агент сначала сгенерирует MockAPI структуру вход/выход и затем вокруг этого строит всю логику. Это должно сильно уменьшит затраты на этапе отладки.



. В следующем эксперименте с Vibe-coding проектом хочу добавить контроль качества проектов. LLM генерирует много спагетти кода, было бы классно если был слой модератора, который следит за качеством архитектуры и кода. 
- попробовать TDD методологию, чтобы на этапе декомпозиции были точные рамки и формализованные критерии для AI-программиста
- добавить в prompt ведение release и feature веток
- добавить MCP-тул создания PullRequest 
- добавить AI-агента критика для CodeReview pull request
- отдельный MCP-тул для генерации API документации
- как запускать параллельно 2 и более агентов в одном проекте?

- вынести логику e2e тестирования в другую программу
- 

## Заключение